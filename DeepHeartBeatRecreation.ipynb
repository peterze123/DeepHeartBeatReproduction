{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5SFOE54UNlIM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746642834049,"user_tz":240,"elapsed":19154,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}},"outputId":"565ec036-7a5c-4823-9ac0-f46a32cd23b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# move to desginated directory\n","import os\n","os.chdir('/content/drive/MyDrive/DLH Final Project/')"]},{"cell_type":"code","source":["import csv\n","import numpy as np\n","import os as os\n","import pandas as pd\n","import scipy.io\n","import skvideo.io\n","import tensorflow as tf"],"metadata":{"id":"filopFoFa_y_","executionInfo":{"status":"ok","timestamp":1746642884029,"user_tz":240,"elapsed":12956,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["ECG Model Training Attempt from resources given from DeepHeartBeat (We were not able to reproduce using the code provided, given the core problem of having different dependencies, as the code largely depended on TF2.2.0)"],"metadata":{"id":"iZymAnTW5Hw7"}},{"cell_type":"code","source":["# physio_data processing\n","physio_data = dict()\n","\n","for filename in os.listdir('data/physio_training/'):\n","  if filename.endswith('.mat'):\n","    mat_data = scipy.io.loadmat('data/physio_training/'+ filename)\n","    physio_data[filename[:-4]] = {\n","        'measurements': mat_data['val'][0],\n","        'frequency': 300\n","    }"],"metadata":{"id":"mzEzuj-GartF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn.model_selection import train_test_split\n","# from models.ecg import ECGModel"],"metadata":{"id":"d2qGgb8Gnd9R","executionInfo":{"status":"ok","timestamp":1746643913818,"user_tz":240,"elapsed":23556,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# # Load Physionet ECG data\n","# print('%i subjects loaded' % len(physio_data))\n","\n","# # Train-validation split\n","# ids = np.array(list(physio_data.keys()))\n","# train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=38)\n","\n","# train_data = [physio_data[id] for id in train_ids]\n","# val_data = [physio_data[id] for id in val_ids]"],"metadata":{"id":"1sxa4DhxadtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# trained_model_path = './self_trained_models/physionet'\n","# model = ECGModel(latent_space_dim=8, batch_size=64, hidden_dim=128, learning_rate=5e-4, log_dir=trained_model_path)\n","# model.fit(train_data, val_data)\n","\n","# model.save_weights(trained_model_path)"],"metadata":{"id":"kguof9kInkiW","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ECG Model (self reproduction with help of LLM)\n","\n","\n","* Ablation in a function window_data to normalize\n"],"metadata":{"id":"ugCCQ87GW70Y"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","# Constants\n","WINDOW_SIZE = 256\n","STRIDE = 128\n","EPOCHS = 10\n","BATCH_SIZE = 16\n","LATENT_DIM = 32  # size of latent vector\n","\n","# Normalize + Windowing\n","def window_data(data_dict, window_size, stride):\n","    all_windows = []\n","    for sample in data_dict.values():\n","        signal = sample['measurements']\n","        for start in range(0, len(signal) - window_size + 1, stride):\n","            window = signal[start:start + window_size]\n","            # Normalize: zero mean, unit variance\n","            window = (window - np.mean(window)) / (np.std(window) + 1e-8)\n","            all_windows.append(window)\n","    return tf.ragged.constant(all_windows, dtype=tf.float32)\n","\n","windows = window_data(physio_data, WINDOW_SIZE, STRIDE)\n","print(f\"Total windows: {windows.shape[0]}\")\n","\n","# Split\n","def split_train_test(ragged_tensor, train_frac=0.8):\n","    total = ragged_tensor.shape[0]\n","    split = int(total * train_frac)\n","    train = ragged_tensor[:split].to_tensor()\n","    test = ragged_tensor[split:].to_tensor()\n","    return train, test\n","\n","train_x, test_x = split_train_test(windows)\n","\n","# Model\n","def build_autoencoder(input_length, latent_dim=LATENT_DIM):\n","    input_layer = layers.Input(shape=(input_length, 1))\n","\n","    # Encoder\n","    x = layers.Conv1D(16, 3, padding='same', activation='relu')(input_layer)\n","    x = layers.MaxPooling1D(2)(x)\n","    x = layers.Conv1D(8, 3, padding='same', activation='relu')(x)\n","    x = layers.MaxPooling1D(2)(x)\n","    x = layers.Flatten()(x)\n","    latent = layers.Dense(latent_dim, name=\"latent_vector\")(x)\n","\n","    # Decoder\n","    x = layers.Dense((input_length // 4) * 8)(latent)\n","    x = layers.Reshape((input_length // 4, 8))(x)\n","    x = layers.UpSampling1D(2)(x)\n","    x = layers.Conv1D(8, 3, padding='same', activation='relu')(x)\n","    x = layers.UpSampling1D(2)(x)\n","    x = layers.Conv1D(1, 3, padding='same', activation='linear')(x)\n","\n","    return models.Model(input_layer, x)\n","\n","# Prepare input\n","train_x = tf.expand_dims(train_x, -1)\n","test_x = tf.expand_dims(test_x, -1)\n","\n","# Build and compile\n","model = build_autoencoder(WINDOW_SIZE)\n","model.compile(optimizer='adam', loss='mse', metrics=['mae','rmse'])\n","\n","history = model.fit(\n","    train_x, train_x,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    validation_data=(test_x, test_x)\n",")\n","\n","# Evaluate with LLM generated metrics, MSE and MAE\n","eval_loss, eval_mae = model.evaluate(test_x, test_x)\n","print(f\"\\nTest MSE: {eval_loss:.4f}, Test MAE: {eval_mae:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYnzUJsvXAoN","executionInfo":{"status":"ok","timestamp":1746647341658,"user_tz":240,"elapsed":102839,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}},"outputId":"92fce289-5af7-4f90-ef2d-416e595b8fb2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Total windows: 13262\n","Epoch 1/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.4533 - mae: 0.3778 - val_loss: 0.0595 - val_mae: 0.1570\n","Epoch 2/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0609 - mae: 0.1520 - val_loss: 0.0449 - val_mae: 0.1318\n","Epoch 3/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0468 - mae: 0.1273 - val_loss: 0.0385 - val_mae: 0.1216\n","Epoch 4/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0397 - mae: 0.1148 - val_loss: 0.0337 - val_mae: 0.1109\n","Epoch 5/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0358 - mae: 0.1088 - val_loss: 0.0301 - val_mae: 0.1041\n","Epoch 6/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0339 - mae: 0.1053 - val_loss: 0.0291 - val_mae: 0.1010\n","Epoch 7/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0316 - mae: 0.1013 - val_loss: 0.0285 - val_mae: 0.0967\n","Epoch 8/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0295 - mae: 0.0984 - val_loss: 0.0277 - val_mae: 0.0988\n","Epoch 9/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0297 - mae: 0.0986 - val_loss: 0.0272 - val_mae: 0.0971\n","Epoch 10/10\n","\u001b[1m664/664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0281 - mae: 0.0963 - val_loss: 0.0258 - val_mae: 0.0938\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0284 - mae: 0.0973\n","\n","Test MSE: 0.0258, Test MAE: 0.0938\n"]}]},{"cell_type":"markdown","source":["Evaluation with Anamaly Detection"],"metadata":{"id":"HAuYMMaASTku"}},{"cell_type":"code","source":["\"\"\"\n","From utils.py in the DeepHeartBeat repo\n","\"\"\"\n","\n","from tqdm import tqdm\n","\n","def get_model_results(model, data_dict, window_size=WINDOW_SIZE, stride=STRIDE):\n","    model_results = dict()\n","\n","    for rec_id, sample in tqdm(data_dict.items(), desc=\"Evaluating model\"):\n","        signal = sample['measurements']\n","        windows = []\n","\n","        for start in range(0, len(signal) - window_size + 1, stride):\n","            window = signal[start:start + window_size]\n","            window = (window - np.mean(window)) / (np.std(window) + 1e-8)\n","            windows.append(window)\n","\n","        if not windows:\n","            continue\n","\n","        windows = np.array(windows)[..., np.newaxis]\n","        reconstructions = model.predict(windows, verbose=0)\n","        errors = np.mean((reconstructions - windows)**2, axis=(1, 2))\n","\n","        model_results[rec_id] = {\n","            'reconstruction_error': float(np.mean(errors)),\n","            'reconstruction_stddev': float(np.mean(np.std(reconstructions, axis=1))),\n","            'num_windows': len(windows),\n","        }\n","\n","    return model_results\n"],"metadata":{"id":"jpBYeBhOM17z","executionInfo":{"status":"ok","timestamp":1746647414415,"user_tz":240,"elapsed":9,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["full_results_train = get_model_results(model, {k: physio_data[k] for k in physio_data.keys()})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAWVBXGxK6W8","executionInfo":{"status":"ok","timestamp":1746647445434,"user_tz":240,"elapsed":24634,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}},"outputId":"2fab89e4-9d25-4b02-a656-a3a069394636"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating model: 100%|██████████| 180/180 [00:24<00:00,  7.31it/s]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","How well does the model do when classifying noises: \"~\" labels\n","\"\"\"\n","\n","from sklearn.metrics import roc_auc_score\n","\n","with open('./data/physio_training/REFERENCE.csv', newline='') as label_csv_file:\n","      csv_reader = csv.reader(label_csv_file, delimiter=',')\n","      labels = {record_id: label for record_id, label in csv_reader}\n","\n","\n","noise_labels = [1 if labels[rec_id] == '~' else 0 for rec_id in full_results_train.keys()]\n","rec_error = [full_results_train[rec_id]['reconstruction_error'] for rec_id in full_results_train.keys()]\n","print(\"ROC AUC score: {}\".format(roc_auc_score(noise_labels, rec_error)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7r1mgxljLTmC","executionInfo":{"status":"ok","timestamp":1746647446173,"user_tz":240,"elapsed":14,"user":{"displayName":"Peter Ze","userId":"08132601757485748790"}},"outputId":"4644d8bd-c07e-425a-9745-3d7bf3935bff"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["ROC AUC score: 0.8116760828625236\n"]}]},{"cell_type":"markdown","source":["EchocardioModel Model Training Attempt (were not able to succeed due to limitations in data processing, need to expand a zip of 8GB and after multiple tries in unzipping, there are still a large portion of missing files that do not match with filelistlabel)"],"metadata":{"id":"WiBhuv1A-k2A"}},{"cell_type":"code","source":["# video_cache_folder = './cache/EchoNet-Dynamic/Videos'\n","\n","# if not os.path.exists(video_cache_folder):\n","#     os.makedirs(video_cache_folder)\n","\n","# data_info = pd.read_csv('./data/EchoNet-Dynamic/FileList.csv')\n","# data_info['globalID'] = data_info['FileName'].apply(lambda s: s[:-4]).astype('string')\n","# data_info.set_index('globalID', inplace=True)\n","\n","# files = dict()\n","# for index, row in data_info.iterrows():\n","#     filepath = './content/drive/MyDrive/DLH Final Project/data/EchoNet-Dynamic/Videos/' + index + '.avi'\n","#     filepath_cached = video_cache_folder + '/' + index + '.npz'\n","\n","#     if not os.path.exists(filepath_cached):\n","\n","#         frames = skvideo.io.vread(filepath)\n","\n","#         frames = [frame[:, :, 0] for frame in frames]\n","\n","#         time_base = 1/data_info.loc[index]['FPS']\n","#         times = [i*time_base for i in range(len(frames))]\n","\n","#         np.savez(filepath_cached, frames=frames, times=times)\n","\n","#     files[index] = filepath_cached"],"metadata":{"id":"__-gt4gS9rSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# echonet_train_ids = data_info[data_info.Split == 'TRAIN'].index.values\n","# echonet_val_ids = data_info[data_info.Split == 'VAL'].index.values\n","# ids = list(echonet_train_ids) + list(echonet_val_ids)\n","\n","# files = np.array([files[id] for id in ids])\n","# kf = KFold(n_splits=5, shuffle=True, random_state=230)\n","# for i, (train_index, val_index) in enumerate(kf.split(files)):\n","\n","#     train_files = files[train_index]\n","#     val_files = files[val_index]\n","\n","#     trained_model_path = './self_trained_modles/echonet_dynamic_' + str(i)\n","\n","#     model = EchocardioModel(latent_space_dim=128, batch_size=32, hidden_dim=128, log_dir=trained_model_path)\n","#     model.fit(train_files, val_files)\n","\n","#     model.save_weights(trained_model_path)"],"metadata":{"id":"bEHZfuvi-x1u"},"execution_count":null,"outputs":[]}]}