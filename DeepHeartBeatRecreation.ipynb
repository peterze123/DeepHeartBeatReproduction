{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5SFOE54UNlIM"},"outputs":[],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# move to desginated directory\n","import os\n","os.chdir('/content/drive/MyDrive/DLH Final Project/')"]},{"cell_type":"code","source":["import csv\n","import numpy as np\n","import os as os\n","import pandas as pd\n","import scipy.io\n","import skvideo.io\n","import tensorflow as tf"],"metadata":{"id":"filopFoFa_y_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ECG Model Training Attempt from resources given from DeepHeartBeat (We were not able to reproduce using the code provided, given the core problem of having different dependencies, as the code largely depended on TF2.2.0)"],"metadata":{"id":"iZymAnTW5Hw7"}},{"cell_type":"code","source":["# physio_data processing\n","physio_data = dict()\n","\n","for filename in os.listdir('data/physio_training/'):\n","  if filename.endswith('.mat'):\n","    mat_data = scipy.io.loadmat('data/physio_training/'+ filename)\n","    physio_data[filename[:-4]] = {\n","        'measurements': mat_data['val'][0],\n","        'frequency': 300\n","    }"],"metadata":{"id":"mzEzuj-GartF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from models.ecg import ECGModel"],"metadata":{"id":"d2qGgb8Gnd9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Physionet ECG data\n","print('%i subjects loaded' % len(physio_data))\n","\n","# Train-validation split\n","ids = np.array(list(physio_data.keys()))\n","train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=38)\n","\n","train_data = [physio_data[id] for id in train_ids]\n","val_data = [physio_data[id] for id in val_ids]"],"metadata":{"id":"1sxa4DhxadtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","trained_model_path = './self_trained_models/physionet'\n","model = ECGModel(latent_space_dim=8, batch_size=64, hidden_dim=128, learning_rate=5e-4, log_dir=trained_model_path)\n","model.fit(train_data, val_data)\n","\n","model.save_weights(trained_model_path)"],"metadata":{"id":"kguof9kInkiW","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ECG Model (self reproduction with help of LLM)\n","\n","*  Ablation in a window_data procesor, but the results after processing, reducing epochs size are still not ideal\n","\n"],"metadata":{"id":"ugCCQ87GW70Y"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","WINDOW_SIZE = 256\n","STRIDE = 128\n","EPOCHS = 10\n","BATCH_SIZE = 16\n","\n","def window_data(data_dict, window_size, stride):\n","    all_windows = []\n","    for sample in data_dict.values():\n","        signal = sample['measurements']\n","        for start in range(0, len(signal) - window_size + 1, stride):\n","            window = signal[start:start + window_size]\n","            all_windows.append(window)\n","    return tf.ragged.constant(all_windows, dtype=tf.float32)\n","\n","windows = window_data(physio_data, WINDOW_SIZE, STRIDE)\n","print(f\"Total windows: {windows.shape[0]}\")\n","\n","def split_train_test(ragged_tensor, train_frac=0.8):\n","    total = ragged_tensor.shape[0]\n","    split = int(total * train_frac)\n","    train = ragged_tensor[:split].to_tensor()\n","    test = ragged_tensor[split:].to_tensor()\n","    return train, test\n","\n","train_x, test_x = split_train_test(windows)\n","\n","def build_model(input_shape):\n","    model = models.Sequential([\n","        layers.Input(shape=input_shape),\n","        layers.Reshape((input_shape[0], 1)),\n","        layers.Conv1D(16, 3, activation='relu', padding='same'),\n","        layers.MaxPooling1D(2),\n","        layers.Conv1D(8, 3, activation='relu', padding='same'),\n","        layers.GlobalAveragePooling1D(),\n","        layers.Dense(input_shape[0]),\n","        layers.Reshape((input_shape[0],))\n","    ])\n","    return model\n","\n","model = build_model(train_x.shape[1:])\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","history = model.fit(\n","    train_x, train_x,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    validation_data=(test_x, test_x)\n",")\n","\n","eval_loss, eval_mae = model.evaluate(test_x, test_x)\n","print(f\"\\nTest MSE: {eval_loss:.4f}, Test MAE: {eval_mae:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYnzUJsvXAoN","executionInfo":{"status":"ok","timestamp":1746599057143,"user_tz":240,"elapsed":157173,"user":{"displayName":"Peter Ze","userId":"16946088462855680097"}},"outputId":"923dc550-5f52-4dbd-8164-849ed3af09c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total windows: 50834\n","Epoch 1/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - loss: 54188.5742 - mae: 120.7465 - val_loss: 50506.8672 - val_mae: 118.5531\n","Epoch 2/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 47858.4258 - mae: 117.4641 - val_loss: 50540.6016 - val_mae: 117.9903\n","Epoch 3/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 49336.3086 - mae: 117.9712 - val_loss: 50430.1758 - val_mae: 118.3711\n","Epoch 4/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - loss: 50040.8711 - mae: 119.0928 - val_loss: 50394.4688 - val_mae: 118.6937\n","Epoch 5/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - loss: 48966.3750 - mae: 117.9886 - val_loss: 50394.2227 - val_mae: 117.5844\n","Epoch 6/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 51864.8711 - mae: 118.9607 - val_loss: 50249.5195 - val_mae: 118.2433\n","Epoch 7/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 49070.8164 - mae: 117.8575 - val_loss: 50121.0859 - val_mae: 117.9112\n","Epoch 8/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 50731.8203 - mae: 118.5851 - val_loss: 50085.9062 - val_mae: 117.2922\n","Epoch 9/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - loss: 49323.1211 - mae: 117.3251 - val_loss: 49809.7969 - val_mae: 116.9010\n","Epoch 10/10\n","\u001b[1m2542/2542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 50952.9727 - mae: 118.3346 - val_loss: 49696.0117 - val_mae: 116.2755\n","\u001b[1m318/318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 36277.7500 - mae: 101.6915\n","\n","Test MSE: 49696.0156, Test MAE: 116.2755\n"]}]},{"cell_type":"markdown","source":["EchocardioModel Model Training Attempt (were not able to succeed due to limitations in data processing, need to expand a zip of 8GB and after multiple tries in unzipping, there are still a large portion of missing files that do not match with filelistlabel)"],"metadata":{"id":"WiBhuv1A-k2A"}},{"cell_type":"code","source":["video_cache_folder = './cache/EchoNet-Dynamic/Videos'\n","\n","if not os.path.exists(video_cache_folder):\n","    os.makedirs(video_cache_folder)\n","\n","data_info = pd.read_csv('./data/EchoNet-Dynamic/FileList.csv')\n","data_info['globalID'] = data_info['FileName'].apply(lambda s: s[:-4]).astype('string')\n","data_info.set_index('globalID', inplace=True)\n","\n","files = dict()\n","for index, row in data_info.iterrows():\n","    filepath = './content/drive/MyDrive/DLH Final Project/data/EchoNet-Dynamic/Videos/' + index + '.avi'\n","    filepath_cached = video_cache_folder + '/' + index + '.npz'\n","\n","    if not os.path.exists(filepath_cached):\n","\n","        frames = skvideo.io.vread(filepath)\n","\n","        frames = [frame[:, :, 0] for frame in frames]\n","\n","        time_base = 1/data_info.loc[index]['FPS']\n","        times = [i*time_base for i in range(len(frames))]\n","\n","        np.savez(filepath_cached, frames=frames, times=times)\n","\n","    files[index] = filepath_cached"],"metadata":{"id":"__-gt4gS9rSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["echonet_train_ids = data_info[data_info.Split == 'TRAIN'].index.values\n","echonet_val_ids = data_info[data_info.Split == 'VAL'].index.values\n","ids = list(echonet_train_ids) + list(echonet_val_ids)\n","\n","files = np.array([files[id] for id in ids])\n","kf = KFold(n_splits=5, shuffle=True, random_state=230)\n","for i, (train_index, val_index) in enumerate(kf.split(files)):\n","\n","    train_files = files[train_index]\n","    val_files = files[val_index]\n","\n","    trained_model_path = './self_trained_modles/echonet_dynamic_' + str(i)\n","\n","    model = EchocardioModel(latent_space_dim=128, batch_size=32, hidden_dim=128, log_dir=trained_model_path)\n","    model.fit(train_files, val_files)\n","\n","    model.save_weights(trained_model_path)"],"metadata":{"id":"bEHZfuvi-x1u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ablation in rem"],"metadata":{"id":"HeDrEpA0ATey"}}]}